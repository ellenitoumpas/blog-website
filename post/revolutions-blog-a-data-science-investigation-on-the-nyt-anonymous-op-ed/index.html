<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.48" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>PROJECT BREAKDOWN - A data science investigation on the NYT anonymous op-ed] -  [PART 1] &middot; Elleni Toumpas</title>

  
  <link type="text/css" rel="stylesheet" href="/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="/css/poole.css">
  <link type="text/css" rel="stylesheet" href="/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Elleni Toumpas" />

  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="/"><h1>Elleni Toumpas</h1></a>
      <p class="lead">
      A data related student in Melbourne, Australia.
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="/">Home</a> </li>
        <li><a href="/post/2018-melbourne-datathon/"> 2018 Melbourne Datathon </a></li><li><a href="/post/first-post/"> First Post </a></li><li><a href="/post/revolutions-blog-a-data-science-investigation-on-the-nyt-anonymous-op-ed/"> PROJECT BREAKDOWN - A data science investigation on the NYT anonymous op-ed] -  [PART 1] </a></li><li><a href="/post/turning-java-into-a-web-application/"> Turning Java into a Web Application </a></li>
      </ul>
    </nav>

    <p>&copy; 2018. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>PROJECT BREAKDOWN - A data science investigation on the NYT anonymous op-ed] -  [PART 1]</h1>
  <time datetime=2018-09-10T00:00:00Z class="post-date">Mon, Sep 10, 2018</time>
  <p>Starting a new data anaylsis project at the moment feels so overwhelming. There are so may techniques I currently don’t understand OR am even aware of. To overcome this I have decided to research other data scientists and the steps they take in their own project. By emulating these projects, understanding the initial scope of the project, the tools and algorithms they have used and understanding why they might have chosen those techniques I hope to become more proficient and confident in this industry. I am going to call these blog write ups Project Breakdowns.</p>
<p>My first Project Breakdown is inspired by the <a href="http://blog.revolutionanalytics.com/2018/09/anonymous-nyt-op-ed.html">“Who wrote that anonymous NYT op-ed? Text similarity analyses with R”</a> blog article on the <a href="http://blog.revolutionanalytics.com/">Revolution Analytics</a> website. The article introduces the New York Times anonymous op-ed written by a current White House staffer who reports that many staffers inside the White House are working silently to oppose or thwart Donald Trump’s agenda. The <a href="http://blog.revolutionanalytics.com/">Revolution Analytics</a> then introduces many attempts in the Data Science community to unpack the identity of who that anonymous staffer might be.</p>
<div id="understanding-the-problem-and-steps" class="section level3">
<h3>Understanding the problem and steps</h3>
<p>What this project entails is</p>
</div>
<div id="scraping-tweets" class="section level3">
<h3>Scraping Tweets</h3>
<p>To undertake a project like this it mentions that the task began by scraping the tweets of many White House staffers. How is this done? I am not sure. Let’s research that!</p>
<p>Using the all mighty google I found this article: <a href="http://utstat.toronto.edu/~nathan/teaching/sta4002/Class1/scrapingtwitterinR-NT.html">Scraping Twitter data and using it in R</a></p>
<div id="install-and-load-appropriate-packages" class="section level4">
<h4>1. Install and load appropriate packages</h4>
<pre class="r"><code># INSTALL PACKAGES [only do this once]
# install.packages(&quot;twitteR&quot;)
# install.packages(&quot;tidytext&quot;)
# install.packages(&quot;dplyr&quot;)
# install.packages(&quot;ggplot2&quot;)
# install.packages(&quot;scales&quot;)
# install.packages(&quot;broom&quot;)

# LOAD PACKAGES
library(twitteR)
library(tidytext)
library(dplyr)
library(ggplot2)
library(stringr)
library(purrr)
library(tidyr)
library(lubridate)
library(scales)
library(broom)</code></pre>
</div>
<div id="set-up-twitter" class="section level4">
<h4>2. Set up Twitter</h4>
<ul>
<li>You need to have a twitter account</li>
<li>Sign up to <a href="https://apps.twitter.com/" class="uri">https://apps.twitter.com/</a> with your account</li>
<li>Once approved click on the “Create an app” link.</li>
<li>Fill in the details as needed</li>
</ul>
</div>
<div id="fill-in-authorisation-details" class="section level4">
<h4>3. Fill in Authorisation details</h4>
<pre class="r"><code># Replace consumer_key_nt, consumer_secret_nt, access_token_nt and access_secret_nt with your own API keys

# consumer_key &lt;- consumer_key_nt
# consumer_secret &lt;- consumer_secret_nt
# access_token &lt;- access_token_nt
# access_secret &lt;- access_secret_nt

# setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)</code></pre>
<pre><code>## [1] &quot;Using direct authentication&quot;</code></pre>
</div>
<div id="using-the-twitter-package-in-r" class="section level4">
<h4>4. Using the Twitter Package in R</h4>
<p>** What can the TwitteR package do? **</p>
<p>Here are some notes and tutorials on what the TwitteR package for R can do.</p>
<p><a href="http://geoffjentry.hexdump.org/twitteR.pdf" class="uri">http://geoffjentry.hexdump.org/twitteR.pdf</a></p>
<ul>
<li>searchTwitter - search for tweets that match a desired term e.g. hashtags, basic boolean logic such as AND and OR.</li>
</ul>
<pre class="r"><code># Grab latest tweets example
tweets_sanders &lt;- searchTwitter(&#39;@BernieSanders&#39;, n=1500)
head(tweets_sanders)</code></pre>
<pre><code>## [[1]]
## [1] &quot;somenycguy: @Lcoyote93 @benshapiro @BernieSanders I can’t wait!&quot;
## 
## [[2]]
## [1] &quot;cheyenne_groth: I voted for @BernieSanders in the primary, but I&#39;m regretting that vote. Jeffrey is the 4th black person I&#39;ve seen… https://t.co/cZgmr5JNY8&quot;
## 
## [[3]]
## [1] &quot;BLK_Z51: @RonSwanson19 @SirKnicksAlot @BernieSanders Everyone knows you can&#39;t trust Google anymore.&quot;
## 
## [[4]]
## [1] &quot;glavema: RT @BernieSanders: We live in a nation that spent centuries denying the right to vote to the poor, to women, and to people of color. We mus…&quot;
## 
## [[5]]
## [1] &quot;LisaM3732: @NaphiSoc @SallyDeal4 Time to #PostponeTheVote and have an #FBIInvestigationNow @SenatorCollins @lisamurkowski… https://t.co/jomgEY1390&quot;
## 
## [[6]]
## [1] &quot;_TrumpFanPage: @BernieSanders and @Ocasio2018:\nAmerica is the greatest country in the world.\nWe defeated:\nSlavery \nNazis \nCommunis… https://t.co/GfqTPhQ8vK&quot;</code></pre>
</div>
</div>
<div id="scraping-a-users-tweet-history" class="section level1">
<h1>Scraping a user’s tweet history</h1>
<p>Understanding how to scrape a user’s tweets. Even though n = 3200, this script only imports 304 of Obama’s tweets. At a later date I will investigate why (I imagine it is due to limits based on my ‘level’ of Developer account access). It is interesting to see what detail can be brought in using this script.</p>
<pre class="r"><code># Scrape a user&#39;s tweets
obamatweets &lt;- userTimeline(&quot;potus44&quot;, n = 3200)
obamatweets_df &lt;- tbl_df(map_df(obamatweets, as.data.frame))
head(obamatweets_df)</code></pre>
<pre><code>## # A tibble: 6 x 16
##   text     favorited favoriteCount replyToSN created             truncated
##   &lt;chr&gt;    &lt;lgl&gt;             &lt;dbl&gt; &lt;chr&gt;     &lt;dttm&gt;              &lt;lgl&gt;    
## 1 I&#39;m sti… FALSE           802905. POTUS44   2017-01-20 14:13:35 FALSE    
## 2 As we l… FALSE           207192. POTUS44   2017-01-20 14:11:01 FALSE    
## 3 I won&#39;t… FALSE           600418. POTUS44   2017-01-20 14:09:51 FALSE    
## 4 It&#39;s be… FALSE          1612269. &lt;NA&gt;      2017-01-20 14:09:13 FALSE    
## 5 Proud t… FALSE           227274. &lt;NA&gt;      2017-01-19 20:39:46 TRUE     
## 6 To the … FALSE          1176101. &lt;NA&gt;      2017-01-17 14:59:24 TRUE     
## # ... with 10 more variables: replyToSID &lt;chr&gt;, id &lt;chr&gt;,
## #   replyToUID &lt;chr&gt;, statusSource &lt;chr&gt;, screenName &lt;chr&gt;,
## #   retweetCount &lt;dbl&gt;, isRetweet &lt;lgl&gt;, retweeted &lt;lgl&gt;, longitude &lt;lgl&gt;,
## #   latitude &lt;lgl&gt;</code></pre>
<pre class="r"><code>dim(obamatweets_df)</code></pre>
<pre><code>## [1] 304  16</code></pre>
<p>Other bits…</p>
<pre class="r"><code>yeswecan &lt;- searchTwitter(&quot;#yeswecan exclude:retweets&quot;, n=3200)</code></pre>
<pre><code>## Warning in doRppAPICall(&quot;search/tweets&quot;, n, params = params,
## retryOnRateLimit = retryOnRateLimit, : 3200 tweets were requested but the
## API can only return 856</code></pre>
<pre class="r"><code>yeswecan &lt;- tbl_df(map_df(yeswecan, as.data.frame))
head(yeswecan)</code></pre>
<pre><code>## # A tibble: 6 x 16
##   text     favorited favoriteCount replyToSN created             truncated
##   &lt;chr&gt;    &lt;lgl&gt;             &lt;dbl&gt; &lt;chr&gt;     &lt;dttm&gt;              &lt;lgl&gt;    
## 1 #VoteTh… FALSE                0. &lt;NA&gt;      2018-09-24 01:06:09 TRUE     
## 2 @Kokomo… FALSE                0. Kokomoth… 2018-09-24 00:47:28 TRUE     
## 3 &quot;@4YrsT… FALSE                0. 4YrsToday 2018-09-24 00:43:03 FALSE    
## 4 @leelee… FALSE                0. leeleeb50 2018-09-24 00:06:21 FALSE    
## 5 &quot;😂😍🤘🏻 #… FALSE                0. &lt;NA&gt;      2018-09-23 23:48:22 FALSE    
## 6 If we c… FALSE                0. &lt;NA&gt;      2018-09-23 23:39:39 FALSE    
## # ... with 10 more variables: replyToSID &lt;chr&gt;, id &lt;chr&gt;,
## #   replyToUID &lt;chr&gt;, statusSource &lt;chr&gt;, screenName &lt;chr&gt;,
## #   retweetCount &lt;dbl&gt;, isRetweet &lt;lgl&gt;, retweeted &lt;lgl&gt;, longitude &lt;chr&gt;,
## #   latitude &lt;chr&gt;</code></pre>
<p>Mission 1 complete. I now have a Twitter developer account and understand how to scrape Twitter feeds. In a further Part to this Project Breakdown I want to investigate how the analysis was carried out.</p>
<p>As always I have a never ending amount of questions I’d like to answer so I will leave them here to remind myself of further topics or ideas to explore.</p>
<p><strong>RESEARCH:</strong></p>
<ul>
<li><p>what are the limits to how many and capacity of Twitter scraping?</p></li>
<li><p>if I did this constantly how do I store/ automate scraping to build a library??</p></li>
<li><p>what is the tbl_df/ map_df code??</p></li>
<li><p>what analysis style was used to work out potential authors</p></li>
<li><p>look into further speech recognition projects and how they can be useful</p></li>
<li><p>consider the moral implicatons of using this kind of technology: when could it be used for good, what are my own boundaries with this kind of thing?</p></li>
</ul>
<p>Until next time…</p>
<p><strong>REFERENCES:</strong></p>
<p><a href="http://www.interhacktives.com/2017/01/25/scrape-tweets-r-journalists/" class="uri">http://www.interhacktives.com/2017/01/25/scrape-tweets-r-journalists/</a></p>
<p><a href="http://varianceexplained.org/r/op-ed-text-analysis/">David Robinson</a></p>
</div>

</div>


    </main>

    
  </body>
</html>
